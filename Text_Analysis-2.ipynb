{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKBeOPN4jwtk"
   },
   "source": [
    "## Training a BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKq0IZKIj2lg"
   },
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the file for Model Training\n",
    "file_path = \"z639_assignment1_training.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Converting to Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the structure of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ud6w6X_ykAQc"
   },
   "source": [
    "Extracting the label with majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine if a given comment is toxic or not based on majority voting\n",
    "def determine_toxicity(composite_toxic):\n",
    "    toxicity_votes = [entry[0] for entry in composite_toxic]  # Extracting True/False votes\n",
    "    return sum(toxicity_votes) > (len(toxicity_votes) / 2)  # Returns the label with Majority wins\n",
    "\n",
    "# Applying the function to extract the final label\n",
    "df[\"is_toxic\"] = df[\"composite_toxic\"].apply(determine_toxicity)\n",
    "\n",
    "# Displaying only the necessary columns\n",
    "df_cleaned = df[[\"text\", \"platform_id\",\"is_toxic\"]]\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whbEmuDokTa_"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Loading pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "encoded_data = tokenizer(\n",
    "    df_cleaned[\"text\"].tolist(),   # Tokenizes all the comments\n",
    "    padding=\"max_length\",          # Ensuring it has uniform input size\n",
    "    truncation=True,               # Truncates longer comments\n",
    "    max_length=128,                # Maximum token length\n",
    "    return_tensors=\"pt\"            # Returns PyTorch tensors\n",
    ")\n",
    "\n",
    "# Extracting tokenized inputs\n",
    "input_ids = encoded_data[\"input_ids\"]\n",
    "attention_mask = encoded_data[\"attention_mask\"]\n",
    "\n",
    "# Checking tokenization output for first few samples\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMwczi25koqx"
   },
   "source": [
    "## Converting Tokenized Data into PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining a PyTorch Dataset Class\n",
    "class ToxicityDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "# Ensuring labels are in tensor format\n",
    "labels = torch.tensor(df_cleaned[\"is_toxic\"].values, dtype=torch.long)\n",
    "\n",
    "# Splitting tokenized data\n",
    "train_ids, val_ids, train_mask, val_mask, train_labels, val_labels = train_test_split(\n",
    "    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Validation Labels Shape:\", val_labels.shape)\n",
    "\n",
    "# Defining Dataset Objects\n",
    "train_dataset = ToxicityDataset(train_ids, train_mask, train_labels)\n",
    "val_dataset = ToxicityDataset(val_ids, val_mask, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiY3HoYqncTw"
   },
   "source": [
    "## Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# batch size recommended for BERT\n",
    "batch_size = 16\n",
    "\n",
    "# Creating DataLoader for Training\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Creating DataLoader for Validation\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Checking Batch Structure\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWV9x2NQn1Yc"
   },
   "source": [
    "## Loading the trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Modifying dropout to prevent overfitting\n",
    "config = BertConfig.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.4,\n",
    "    attention_probs_dropout_prob=0.4\n",
    ")\n",
    "\n",
    "#Loading model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZipYDt4oUvh"
   },
   "source": [
    "## Defining Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    learning_rate=1e-5,  #Lower LR for fine-tuning\n",
    "    lr_scheduler_type=\"cosine\",  #Using cosine decay for better generalization\n",
    "    load_best_model_at_end=True,  #Automatically loads the best model\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=2,  # Keeps only the best 2 models\n",
    "    save_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Computing class weights to Handle imbalance\n",
    "toxic_count = df_cleaned[\"is_toxic\"].sum()\n",
    "non_toxic_count = len(df_cleaned) - toxic_count\n",
    "class_weights = torch.tensor([1.0 / non_toxic_count, 1.0 / toxic_count], dtype=torch.float32).to(device)\n",
    "\n",
    "# Defining weighted loss function\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "# Defining Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\").to(torch.long)  # Ensuring labels are long type\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Early stopping if no improvement\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDodTODNwt-6"
   },
   "source": [
    "The loss is decreasing significantly which indicates that the model is learning well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nCrMJd4xntS"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Storing predictions and actual labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Get model output\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Removing Adaptive Threshold\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        threshold = 0.55  # Fixed threshold instead of dynamic adjustment\n",
    "        preds = (probs[:, 1] > threshold).long()\n",
    "\n",
    "        # Store results\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert results to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# âœ… Computing Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Model Evaluation:\")\n",
    "print(\"Model Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq8UQFpn7iSz"
   },
   "source": [
    "The overall Model Accuracy is almost 75% which is decent. The classification report shows that the model is better at detecting toxic comments than avoiding false alarms. High Precision for Non-Toxic shows Very few non-toxic comments are incorrectly flagged as toxic.\n",
    "High Recall for Toxic shows most toxic comments are detected correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY4Mv-5s4hoB"
   },
   "source": [
    "Visualizing the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Toxic\", \"Toxic\"], yticklabels=[\"Non-Toxic\", \"Toxic\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CdcYTZn8ZpA"
   },
   "source": [
    "440 correct non-toxic classifications (True Negatives)\n",
    "\n",
    "159 correctly detected toxic comments (True Positives)\n",
    "\n",
    "150 false positives (non-toxic comments wrongly marked toxic)\n",
    "\n",
    "51 false negatives (missed toxic comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model and tokenizer\n",
    "model.save_pretrained(\"bert_toxic_classifier\")\n",
    "tokenizer.save_pretrained(\"bert_toxic_classifier\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mPKaywI6LAw"
   },
   "source": [
    "## Predictions on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Loading Test Dataset\n",
    "test_file_path = \"z639_assignment1_test.json\"\n",
    "\n",
    "with open(test_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_data = [json.loads(line) for line in file]\n",
    "\n",
    "df_test = pd.DataFrame(test_data)\n",
    "test_texts = df_test[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W23tx-TC6Q4N"
   },
   "source": [
    "## Tokenization of Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Test Dataset\n",
    "encoded_test = tokenizer(\n",
    "    test_texts,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "test_input_ids = encoded_test[\"input_ids\"]\n",
    "test_attention_mask = encoded_test[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(input_ids, attention_mask):\n",
    "    inputs = {\n",
    "        \"input_ids\": input_ids.to(device),\n",
    "        \"attention_mask\": attention_mask.to(device)\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return True if torch.argmax(probs) == 1 else False\n",
    "\n",
    "#Prediction for All Test Comments\n",
    "df_test[\"prediction\"] = [\n",
    "    predict_toxicity(test_input_ids[i].unsqueeze(0), test_attention_mask[i].unsqueeze(0))\n",
    "    for i in range(len(test_texts))\n",
    "]\n",
    "\n",
    "# Converting Boolean Predictions to Lowercase Strings\n",
    "df_test[\"prediction\"] = df_test[\"prediction\"].astype(str).str.lower()\n",
    "\n",
    "# Displaying Predictions\n",
    "print(df_test[[\"platform_id\", \"prediction\"]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prediction file\n",
    "Prediction = df_test[[\"platform_id\", \"prediction\"]]\n",
    "Prediction.to_csv(\"Prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhiXPMPGaJt9"
   },
   "source": [
    "## Trainin a SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZPTPCpA80Uw"
   },
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training dataset\n",
    "train_file_path = \"z639_assignment1_training.json\"\n",
    "with open(train_file_path, \"r\") as file:\n",
    "    train_data = [json.loads(line) for line in file]\n",
    "\n",
    "# Converting to DataFrame\n",
    "df_train = pd.DataFrame(train_data)\n",
    "\n",
    "# Checking the structure\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyyxHEihHT_v"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters and numbers\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords.words(\"english\")])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Applying text cleaning\n",
    "df_train[\"clean_text\"] = df_train[\"text\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# Function to get majority vote on toxicity\n",
    "def get_majority_label(toxic_list):\n",
    "    return sum(label[0] for label in toxic_list) > len(toxic_list) / 2  # Returns True or False based on majority vote\n",
    "\n",
    "# Applying majority vote to get final label\n",
    "df_train[\"is_toxic\"] = df_train[\"composite_toxic\"].apply(get_majority_label).astype(bool)\n",
    "df_train = df_train[[\"clean_text\", \"is_toxic\"]]\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u8cLHBlIJFe"
   },
   "source": [
    "## Special Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization to convert text data into numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\", ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "y_train = df_train[\"is_toxic\"]\n",
    "\n",
    "# Converting to array\n",
    "X_train = X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ5rUBrAJTRD"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "cv_scores = cross_val_score(svm_model, X_train_final, y_train_final, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Train final SVM model\n",
    "svm_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on training data (for evaluation)\n",
    "y_train_pred = svm_model.predict(X_train_final)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_train_final, y_train_pred)\n",
    "classification_rep = classification_report(y_train_final, y_train_pred)\n",
    "conf_matrix = confusion_matrix(y_train_final, y_train_pred)\n",
    "\n",
    "print(\"Model Evaluation\")\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_train_final, y_train_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Toxic\", \"Toxic\"], yticklabels=[\"Non-Toxic\", \"Toxic\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load test dataset\n",
    "test_file_path = \"z639_assignment1_test.json\"\n",
    "\n",
    "with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "df_test = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning function\n",
    "df_test[\"clean_text\"] = df_test[\"text\"].fillna(\"\").apply(clean_text)\n",
    "\n",
    "print(\"Test dataset loaded and preprocessed.\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test text using the trained TF-IDF vectorizer\n",
    "X_test_tfidf = vectorizer.transform(df_test[\"clean_text\"])\n",
    "\n",
    "print(\"Test data transformed using TF-IDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using trained SVM model\n",
    "test_predictions = svm_model.predict(X_test_tfidf.toarray())\n",
    "\n",
    "# Storing predictions in DataFrame (as True/False)\n",
    "df_test[\"predicted_toxicity\"] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a CSV file\n",
    "df_test[[\"platform_id\", \"predicted_toxicity\"]].to_csv(\"svm_test_predictions.csv\", index=False)\n",
    "\n",
    "# Show sample predictions\n",
    "print(df_test[[\"platform_id\", \"predicted_toxicity\"]].head(20))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
